import streamlit as st
from PIL import Image
import cv2
import numpy as np
import time
from ultralytics import YOLO
import os

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ---
MODELS = {
    "YOLOv8n": "runs/best/yolov8n.pt",
    "YOLOv8s": "yolov8s.pt",
    "Faster R-CNN (COCO)": "faster_rcnn_R_50_FPN_3x.yaml"  # –ü—Ä–∏–º–µ—Ä, –Ω—É–∂–Ω—ã –≤–µ—Å–∞
}
ALLOWED_EXTENSIONS = ["jpg", "jpeg", "png", "mp4", "gif", "tiff", "tif"]


# --- –§—É–Ω–∫—Ü–∏–∏ ---
def load_model(model_name):
    if "YOLO" in model_name:
        return YOLO(MODELS[model_name])
    else:
        raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")


def process_image(model, image):
    # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª ‚Äî —ç—Ç–æ PIL.Image
    if isinstance(image, Image.Image):
        if image.mode == "RGBA":
            image = image.convert("RGB")
        image_np = np.array(image)
    # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ numpy-–º–∞—Å—Å–∏–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–∞–¥—Ä –≤–∏–¥–µ–æ)
    else:
        image_np = image

    results = model.predict(image_np)
    annotated_image = results[0].plot()
    annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
    return annotated_image, len(results[0].boxes)


def process_video(model, video_path):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frames = []
    metrics = {"mAP50": 0.0, "IoU": 0.0}

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # –î–µ—Ç–µ–∫—Ü–∏—è –∏ —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ (–∑–∞–≥–ª—É—à–∫–∞)
        processed_frame, _ = process_image(model, frame)
        frames.append(processed_frame)

    cap.release()
    return frames, fps, metrics


# --- –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
st.title("üî´ Weapon Detector")
model_name = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", list(MODELS.keys()))
uploaded_file = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ/–≤–∏–¥–µ–æ",
    type=ALLOWED_EXTENSIONS,
    help=f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(ALLOWED_EXTENSIONS)}"
)

if uploaded_file:
    model = load_model(model_name)
    file_ext = uploaded_file.name.split(".")[-1].lower()

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ç–æ
    if file_ext in ["jpg", "jpeg", "png", "tiff", "tif"]:
        image = Image.open(uploaded_file)
        image_np = np.array(image)

        with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º..."):
            result_image, detections = process_image(model, image_np)
            st.image(result_image, caption="–†–µ–∑—É–ª—å—Ç–∞—Ç", use_column_width=True)

            if detections == 0:
                st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å.")
            else:
                st.success(f"–ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {detections}")

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –±–∞–π—Ç—ã
                img_bytes = cv2.imencode(".jpg", result_image)[1].tobytes()

                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
                    data=img_bytes,
                    file_name="detected_image.jpg",
                    mime="image/jpeg"
                )


    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ/GIF
    elif file_ext in ["mp4", "gif"]:
        temp_path = f"temp.{file_ext}"
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.read())

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
        cap = cv2.VideoCapture(temp_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        progress_bar = st.progress(0)
        status_text = st.empty()

        # –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        output_path = "output.mp4"
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –∫–∞–¥—Ä–∞–º
        for frame_num in range(total_frames):
            ret, frame = cap.read()
            if not ret:
                break

            # –î–µ—Ç–µ–∫—Ü–∏—è –∏ –∑–∞–ø–∏—Å—å –∫–∞–¥—Ä–∞
            processed_frame, _ = process_image(model, frame)
            out.write(cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR))

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress = (frame_num + 1) / total_frames
            progress_bar.progress(progress)
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {frame_num + 1}/{total_frames} –∫–∞–¥—Ä–æ–≤")

        cap.release()
        out.release()

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        st.video(output_path)

        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        with open(output_path, "rb") as f:
            st.download_button(
                label="–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π",
                data=f,
                file_name="detected_video.mp4",
                mime="video/mp4"
            )

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        os.remove(temp_path)
        os.remove(output_path)

else:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")


# --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ ---
@st.cache_data
def check_file(file):
    if file is None:
        return False
    ext = file.name.split(".")[-1].lower()
    return ext in ALLOWED_EXTENSIONS


if uploaded_file and not check_file(uploaded_file):
    st.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞!")